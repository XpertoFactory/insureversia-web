---
title: "Don't Hide Your AI Use When Disclosure Is Required"
number: 5
description: "Hiding AI use when transparency is required — by regulators, policyholders, or industry partners — creates trust violations that are far more damaging than the AI use itself. The regulatory trend is clearly toward greater transparency, not less."
risk: "Regulatory penalties, loss of license, damaged reputation, policyholder litigation, reinsurance treaty violations, market conduct findings"
realExample: "In 2024, multiple state insurance departments began requesting information about insurers' use of AI in underwriting and claims decisions as part of regular market conduct examinations. Insurers that could not demonstrate transparent AI governance — including documentation of how AI was used, what oversight was in place, and what disclosure was provided to consumers — faced additional scrutiny and, in some cases, corrective action requirements."
mitigation: "Develop a proactive transparency strategy. Know your disclosure obligations in every jurisdiction. Document your AI use systematically. When in doubt, disclose more rather than less — transparency builds trust."
insureversiasTake: "Here's the thing about hiding AI use: it only works until it doesn't. And when it stops working — when a regulator asks, when a policyholder challenges a decision, when a reinsurer audits your processes — the cover-up is always worse than the original use. AI use in insurance is not inherently problematic. Hiding it is. Build disclosure into your process from day one, and you'll never have to explain why you didn't."
sources:
  - type: regulation
    title: "NAIC Model Bulletin on the Use of Artificial Intelligence"
    author: "National Association of Insurance Commissioners"
    date: "2023-12-04"
    note: "Establishes transparency expectations for AI use in insurance"
  - type: regulation
    title: "EU AI Act - Transparency Requirements"
    date: "2024-03-13"
    note: "Requires transparency and disclosure for AI systems classified as high-risk, including certain insurance applications"
---

## The Danger in Detail

The insurance industry is built on trust. Policyholders trust that their coverage decisions are made fairly. Regulators trust that insurers comply with applicable laws. Reinsurers trust that cedents' underwriting and claims practices are sound. Hiding AI use undermines all of these trust relationships.

### Where Disclosure Is Required or Expected

**Regulatory**: The NAIC Model Bulletin expects insurers to maintain documentation of AI systems used in any insurance function. Colorado SB 21-169 requires specific governance and testing documentation for AI used in insurance decisions. The EU AI Act requires transparency for high-risk AI systems.

**Policyholder-facing**: When AI materially influences underwriting decisions, pricing, or claims outcomes, many jurisdictions are moving toward requiring consumer disclosure. Even where not yet required, proactive disclosure is a best practice.

**Reinsurance**: Reinsurance treaties may include provisions about underwriting and claims handling practices. Undisclosed AI use could constitute a material change that triggers notification requirements.

**Internal**: Board-level and management reporting should include information about AI adoption, governance, and risk management.

### Building a Disclosure Framework

1. **Map your AI touchpoints**: Where does AI influence decisions across your organization?
2. **Identify disclosure triggers**: What regulatory, contractual, and ethical obligations apply?
3. **Create standard disclosures**: Develop clear, consistent language for different contexts.
4. **Automate where possible**: Build disclosure into your workflows so it happens automatically.
5. **Document everything**: Maintain records of what was disclosed, to whom, and when.
